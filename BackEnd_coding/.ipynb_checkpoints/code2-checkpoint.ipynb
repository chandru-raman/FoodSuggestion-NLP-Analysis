{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae0050e-58d8-4e07-86cc-5c1d2993796d",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49699f17-fabb-4133-98ac-bdeb600d2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker  # For spell correction\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf91467-1950-4903-a70f-901d7066d9f6",
   "metadata": {},
   "source": [
    "### Step 1: Download necessary NLTK resources (if not already downloaded)\n",
    "##### nltk.download('punkt')\n",
    "##### nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cc607e7-c41f-4df1-b162-3cc91777361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample positive and negative words lists (You can expand these lists as needed)\n",
    "positive_words = ['love', 'amazing', 'great', 'fantastic', 'happy', 'good', 'excellent', 'positive']\n",
    "negative_words = ['worst', 'bad', 'hate', 'horrible', 'poor', 'negative', 'disappointing', 'sad']\n",
    "\n",
    "# Initialize spell checker\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c9820-2774-411a-bcae-57a02975c650",
   "metadata": {},
   "source": [
    "### Step 2: Load feedback data from an Excel CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f3f2669-d356-4a74-983b-d20d743a75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'D:/Project File/Excel data/Feedback.csv'  # Update this path as needed\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8101d5-ee3c-4258-bec6-9f3425aa2917",
   "metadata": {},
   "source": [
    "### Step 3: Check and print column names to ensure correct column for feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89f3eca9-bf11-49a7-a3a9-b526b6588506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file: Index(['FeedBack'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in the CSV file:\", df.columns)\n",
    "\n",
    "# If no \"FeedBack\" column, attempt to find a suitable one and use it\n",
    "if 'FeedBack' not in df.columns:\n",
    "    # Check if \"feedback\" column exists (in case of lowercase column name)\n",
    "    if 'feedback' in df.columns:\n",
    "        df['FeedBack'] = df['feedback']\n",
    "    else:\n",
    "        raise ValueError(\"The CSV file must contain a 'FeedBack' column, or it must be manually set to the correct column.\")\n",
    "\n",
    "# Convert only the first letter of the feedback to lowercase\n",
    "df['FeedBack'] = df['FeedBack'].apply(lambda x: x[0].lower() + x[1:] if len(x) > 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183928f7-716f-4333-b9d0-b7f27acaf750",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess the feedback text (tokenization, remove stopwords and punctuation, correct spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3801684e-a823-446e-9b48-c40f4817c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Chandru\n",
      "[nltk_data]     R\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28f71eea-b86c-4de8-9600-4329b3a08337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())  # Convert to lowercase to normalize\n",
    "    \n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    # Correct spelling for tokens\n",
    "    tokens = [spell.correction(word) for word in tokens]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply the preprocessing function to the FeedBack column\n",
    "df['Tokens'] = df['FeedBack'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf709a-7c67-4d21-b242-43fb1b1e7487",
   "metadata": {},
   "source": [
    "### Step 5: Handling negations and adjusting sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a3db4a1-d7f2-46c2-bd7c-734518ca6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_negations(tokens):\n",
    "    adjusted_tokens = []\n",
    "    negation_words = ['not', 'never', 'no', 'cannot', 'donâ€™t', \"isn't\", \"aren't\"]\n",
    "    for i, word in enumerate(tokens):\n",
    "        if word in negation_words and i+1 < len(tokens):\n",
    "            # Look for the next word, and flip its sentiment\n",
    "            next_word = tokens[i+1]\n",
    "            if next_word in positive_words:\n",
    "                adjusted_tokens.append('not_' + next_word)  # Mark as negated positive word\n",
    "            elif next_word in negative_words:\n",
    "                adjusted_tokens.append('not_' + next_word)  # Mark as negated negative word\n",
    "            else:\n",
    "                adjusted_tokens.append(next_word)  # Keep the word unchanged if it's not in the sentiment list\n",
    "        else:\n",
    "            adjusted_tokens.append(word)\n",
    "    return adjusted_tokens\n",
    "\n",
    "# Apply the negation handling to the Tokens column\n",
    "df['Adjusted_Tokens'] = df['Tokens'].apply(handle_negations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39a1dc-20cc-42cf-8e5d-c1b2af29a1b7",
   "metadata": {},
   "source": [
    "### Step 6: Analyze Sentiment with Adjusted Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ab38aa1-9c18-42ad-9f83-34b1264cdfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(tokens):\n",
    "    # Count positive and negative words (adjusted with negation)\n",
    "    positive_count = sum(1 for word in tokens if word in positive_words)\n",
    "    negative_count = sum(1 for word in tokens if word in negative_words)\n",
    "    \n",
    "    # Adjust for negations by flipping counts\n",
    "    for word in tokens:\n",
    "        if word.startswith('not_'):\n",
    "            # If a word is marked with 'not_', flip its sentiment\n",
    "            if word[4:] in positive_words:\n",
    "                positive_count -= 1\n",
    "                negative_count += 1\n",
    "            elif word[4:] in negative_words:\n",
    "                negative_count -= 1\n",
    "                positive_count += 1\n",
    "\n",
    "    # Determine the sentiment based on counts\n",
    "    if positive_count > negative_count:\n",
    "        sentiment = 'Positive'\n",
    "    elif negative_count > positive_count:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    \n",
    "    return sentiment, positive_count, negative_count\n",
    "\n",
    "# Apply the sentiment analysis to the adjusted tokens and store results\n",
    "df[['Sentiment', 'Positive_Count', 'Negative_Count']] = df['Adjusted_Tokens'].apply(lambda x: pd.Series(analyze_sentiment(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b864f7-297f-48ff-bb77-474dc4a9e25e",
   "metadata": {},
   "source": [
    "### Step 7: Perform Sentiment Analysis Using TextBlob for a more comprehensive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7200470f-2c89-4bfa-9173-bbec5634a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_blob(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity  # Sentiment polarity: -1 (negative) to 1 (positive)\n",
    "    if sentiment > 0:\n",
    "        return 'Positive'\n",
    "    elif sentiment < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply TextBlob Sentiment Analysis\n",
    "df['Sentiment_TextBlob'] = df['FeedBack'].apply(get_sentiment_blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935768e-deb0-4537-a4ef-662199f8e234",
   "metadata": {},
   "source": [
    "### Step 8: Specify the output directory where you want to store the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc910df3-ffb4-47b3-abae-837bbcd5b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'D:/Project File/Analysed Data'  # Replace with your desired path\n",
    "\n",
    "# Ensure the directory exists, otherwise create it\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Set the full file path for the CSV and Excel output\n",
    "csv_file_path = os.path.join(output_directory, 'feedback_with_sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d996a-ceec-4303-9cb0-89f4844419e7",
   "metadata": {},
   "source": [
    "### Step 9: Save the result to CSV in the specified location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adb9b663-536e-4965-95fe-34d292f80ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed and saved to:\n",
      "CSV: D:/Project File/Analysed Data\\feedback_with_sentiment_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(csv_file_path, index=False)\n",
    "print(f\"Sentiment analysis completed and saved to:\\nCSV: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da6d1e0-6df3-4f21-9df7-48b3390c2d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
